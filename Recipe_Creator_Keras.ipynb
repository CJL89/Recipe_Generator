{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependecies:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gensim.models as gs\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "from numpy import array\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, GlobalMaxPooling1D, Dense, Conv2D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# Configuring Notebook environment:\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 7.5)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients_vector</th>\n",
       "      <th>instructions_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p3pKOD6jIHEcjf20CCXohP8uqkG5dGi</th>\n",
       "      <td>grammie hamblets deviled crab</td>\n",
       "      <td>celery finely chopped green pepper finely chop...</td>\n",
       "      <td>toss ingredients lightly spoon buttered baking...</td>\n",
       "      <td>['celery', 'finely', 'chopped', 'green', 'pepp...</td>\n",
       "      <td>['toss', 'ingredients', 'lightly', 'spoon', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO</th>\n",
       "      <td>infineon raceway baked beans</td>\n",
       "      <td>skirt steak cut inch dicekosher salt fresh cra...</td>\n",
       "      <td>watch make recipe sprinkle steak salt pepper s...</td>\n",
       "      <td>['skirt', 'steak', 'cut', 'inch', 'dicekosher'...</td>\n",
       "      <td>['watch', 'make', 'recipe', 'sprinkle', 'steak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK</th>\n",
       "      <td>southwestern black bean dip</td>\n",
       "      <td>cups dried black beans picked rinsed cups wate...</td>\n",
       "      <td>saucepan let beans soak enough cold water cove...</td>\n",
       "      <td>['cups', 'dried', 'black', 'beans', 'picked', ...</td>\n",
       "      <td>['saucepan', 'let', 'beans', 'soak', 'enough',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5l1yTSYFifF/M2dfbD6DX28WWQpLWNK</th>\n",
       "      <td>sour cream noodle bake</td>\n",
       "      <td>ground chuckone tomato sauce saltfreshly groun...</td>\n",
       "      <td>watch make recipe preheat oven degrees f brown...</td>\n",
       "      <td>['ground', 'chuckone', 'tomato', 'sauce', 'sal...</td>\n",
       "      <td>['watch', 'make', 'recipe', 'preheat', 'oven',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kRBQSWtqYWqtkb34FGeenBSbC32gIdO</th>\n",
       "      <td>sushi renovation</td>\n",
       "      <td>rice brown mediumgrain cookedcup quinoacup swe...</td>\n",
       "      <td>special equipment sushi mat cook brown rice qu...</td>\n",
       "      <td>['rice', 'brown', 'mediumgrain', 'cookedcup', ...</td>\n",
       "      <td>['special', 'equipment', 'sushi', 'mat', 'cook...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  grammie hamblets deviled crab   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO   infineon raceway baked beans   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK    southwestern black bean dip   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK         sour cream noodle bake   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO               sushi renovation   \n",
       "\n",
       "                                                                       ingredients  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  celery finely chopped green pepper finely chop...   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  skirt steak cut inch dicekosher salt fresh cra...   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  cups dried black beans picked rinsed cups wate...   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  ground chuckone tomato sauce saltfreshly groun...   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  rice brown mediumgrain cookedcup quinoacup swe...   \n",
       "\n",
       "                                                                      instructions  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  toss ingredients lightly spoon buttered baking...   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  watch make recipe sprinkle steak salt pepper s...   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  saucepan let beans soak enough cold water cove...   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  watch make recipe preheat oven degrees f brown...   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  special equipment sushi mat cook brown rice qu...   \n",
       "\n",
       "                                                                ingredients_vector  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  ['celery', 'finely', 'chopped', 'green', 'pepp...   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  ['skirt', 'steak', 'cut', 'inch', 'dicekosher'...   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  ['cups', 'dried', 'black', 'beans', 'picked', ...   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  ['ground', 'chuckone', 'tomato', 'sauce', 'sal...   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  ['rice', 'brown', 'mediumgrain', 'cookedcup', ...   \n",
       "\n",
       "                                                               instructions_vector  \n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  ['toss', 'ingredients', 'lightly', 'spoon', 'b...  \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  ['watch', 'make', 'recipe', 'sprinkle', 'steak...  \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  ['saucepan', 'let', 'beans', 'soak', 'enough',...  \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  ['watch', 'make', 'recipe', 'preheat', 'oven',...  \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  ['special', 'equipment', 'sushi', 'mat', 'cook...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/strings/df_clean.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ingredients = gs.Word2Vec(df['ingredients_vector'], min_count=1, size= 25, workers=3, window=3, sg=1)\n",
    "model_instructions = gs.Word2Vec(df['instructions_vector'], min_count=1, size= 25, workers=3, window=3, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_ingredients)\n",
    "# data = model_instructions.most_similar('beef')\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59612, 2) (59612,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['title', 'ingredients', 'instructions'], axis=1)\n",
    "y = df['title'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (47689, 2) (47689,)\n",
      "Test shape: (11923, 2) (11923,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "print('Train shape:', X_train.shape, y_train.shape)\n",
    "print('Test shape:', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(X_train))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ingredients_vector': 0, 'instructions_vector': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(X_train)}\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-56-50584ad557c2>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-56-50584ad557c2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    char2idx = {(u:i for i, u in enumerate(x)) x for x in df['ingredients_vector']}\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:x for i, u in enumerate(x)) x for x in df['ingredients_vector']}\n",
    "idx2char = np.array(df['ingredients_vector'])\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in df['ingredients_vector']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"['celery', 'finely', 'chopped', 'green', 'pepper', 'finely', 'chopped', 'finely', 'sliced', 'green', 'onions', 'chopped', 'parsley', 'crabmeat', 'cups', 'coarsely', 'crushed', 'cracker', 'crumbs', 'salt', 'teaspoons', 'dry', 'mustarddash', 'hot', 'sauce', 'heavy', 'cream', 'melted', 'butter']\": 56784,\n",
      "  \"['skirt', 'steak', 'cut', 'inch', 'dicekosher', 'salt', 'fresh', 'cracked', 'black', 'pepper', 'slices', 'thickcut', 'applewood', 'smoked', 'bacon', 'inch', 'diced', 'cups', 'inch', 'diced', 'red', 'onion', 'seeded', 'finely', 'diced', 'jalapenos', 'tablespoons', 'minced', 'garlic', 'kosher', 'salt', 'teaspoons', 'fresh', 'cracked', 'black', 'pepperapple', 'cider', 'vinegar', 'best', 'quality', 'cannellini', 'beans', 'liquid', 'lima', 'beans', 'liquid', 'kidney', 'beans', 'liquid', 'molasses', 'tablespoons', 'dark', 'brown', 'sugar', 'tablespoons', 'soy', 'sauce', 'ketchupcrusty', 'bread', 'serving']\":   1,\n",
      "  \"['cups', 'dried', 'black', 'beans', 'picked', 'rinsed', 'cups', 'water', 'plus', 'cloves', 'garlic', 'tablespoons', 'vegetable', 'oil', 'green', 'bell', 'pepper', 'finely', 'chopped', 'reserving', 'garnish', 'red', 'onion', 'finely', 'chopped', 'reserving', 'garnish', 'teaspoons', 'ground', 'cumin', 'tablespoons', 'cider', 'vinegarsalt', 'pepper', 'plum', 'tomato', 'finely', 'chopped', 'red', 'chile', 'finely', 'choppedfresh', 'cilantro', 'leaves', 'garnishdollop', 'sour', 'cream', 'garnishserving', 'suggestion', 'tortilla', 'chips']\":   2,\n",
      "  \"['ground', 'chuckone', 'tomato', 'sauce', 'saltfreshly', 'ground', 'black', 'pepper', 'ounces', 'egg', 'noodles', 'sour', 'cream', 'cups', 'curd', 'cottage', 'cheesepinch', 'red', 'pepper', 'flakes', 'sliced', 'green', 'onions', 'less', 'taste', 'grated', 'sharp', 'cheddarcrusty', 'french', 'bread', 'serving']\":   3,\n",
      "  \"['rice', 'brown', 'mediumgrain', 'cookedcup', 'quinoacup', 'sweet', 'red', 'peppers', 'raw', 'white', 'tuna', 'canned', 'water', 'drained', 'solids', 'tbs', 'seaweed', 'kelp', 'rawcup', 'shiitake', 'mushrooms', 'cooked', 'without', 'saltcup', 'carrots', 'rawcup', 'cucumber', 'peel', 'raw', 'oriental', 'radish', 'inches', 'long', 'raw', 'tbs', 'sesame', 'seed', 'kernels', 'toasted', 'without', 'added', 'salt']\":   4,\n",
      "  \"['extravirgin', 'olive', 'oil', 'baby', 'italian', 'eggplants', 'ounces', 'unpeeled', 'cut', 'rounds', 'eachkosher', 'salt', 'roasted', 'garlic', 'hummus', 'prepared', 'hummus', 'cherry', 'grape', 'tomatoes', 'quartered', 'tablespoons', 'fresh', 'flatleaf', 'parsley', 'leaves', 'finely', 'grated', 'lemon', 'zest']\":   5,\n",
      "  \"['lightly', 'crumbled', 'saffron', 'threads', 'sugarkosher', 'salt', 'wide', 'strips', 'orange', 'zest', 'thinly', 'sliced', 'carrot', 'shredded', 'tablespoons', 'unsalted', 'butter', 'onion', 'finely', 'chopped', 'cinnamon', 'green', 'cardamom', 'podssmall', 'pinch', 'ground', 'allspicesmall', 'pinch', 'ground', 'cumin', 'cups', 'basmati', 'rice', 'rinsed', 'well', 'pistachios', 'blanched', 'almonds', 'roughly', 'chopped', 'dried', 'cranberries', 'dried', 'apricots', 'finely', 'chopped', 'tablespoons', 'chopped', 'fresh', 'parsley']\":   6,\n",
      "  \"['topsliced', 'hotdog', 'buns', 'fashion', 'topsliced', 'buns', 'bread', 'tablespoons', 'unsalted', 'butter', 'softened', 'cups', 'coarsely', 'chopped', 'cooked', 'lobster', 'lobsters', 'cool', 'cold', 'tablespoons', 'melted', 'butter', 'tablespoons', 'mayonnaise', 'mixed', 'tablespoons', 'minced', 'celery']\":   7,\n",
      "  \"['green', 'red', 'bell', 'peppers', 'olive', 'oil', 'onions', 'finely', 'chopped', 'pine', 'nutssalt', 'uncooked', 'white', 'rice', 'tomatoes', 'seeded', 'finely', 'chopped', 'currants', 'tablespoons', 'finely', 'chopped', 'fresh', 'mint', 'teaspoons', 'sugar', 'freshly', 'grated', 'nutmeg', 'cups', 'hot', 'water', 'tablespoons', 'fresh', 'lemon', 'juiceolive', 'oil', 'drizzlinglemon', 'wedges', 'garnish']\":   8,\n",
      "  \"['head', 'cauliflower', 'cut', 'bitesize', 'florets', 'cloves', 'garlic', 'roughly', 'chopped', 'tablespoons', 'unsalted', 'butter', 'teaspoons', 'kosher', 'salt', 'fresh', 'bread', 'crumbs', 'see', 'knowhow', 'tablespoons', 'minced', 'fresh', 'flatleaf', 'parsleyfreshly', 'ground', 'black', 'pepperlemon', 'wedges']\":   9,\n",
      "  \"['cups', 'chicken', 'stock', 'preferably', 'homemade', 'recipe', 'follows', 'quart', 'roasted', 'winter', 'vegetables', 'recipe', 'followskosher', 'salt', 'freshly', 'ground', 'black', 'pepper', 'roasting', 'chickens', 'yellow', 'onions', 'unpeeled', 'quartered', 'carrots', 'unpeeled', 'halved', 'celery', 'stalks', 'leaves', 'cut', 'thirds', 'parsnips', 'unpeeled', 'cut', 'sprigs', 'fresh', 'parsley', 'sprigs', 'fresh', 'thyme', 'sprigs', 'fresh', 'dill', 'head', 'garlic', 'unpeeled', 'cut', 'crosswise', 'tablespoons', 'kosher', 'salt', 'teaspoons', 'whole', 'black', 'peppercorns', 'carrots', 'peeled', 'parsnips', 'peeled', 'sweet', 'potato', 'peeled', 'butternut', 'squash', 'peeled', 'seeded', 'tablespoons', 'good', 'olive', 'oil', 'teaspoons', 'kosher', 'salt', 'freshly', 'ground', 'black', 'pepper', 'tablespoons', 'chopped', 'fresh', 'flatleaf', 'parsley']\":  10,\n",
      "  \"['cups', 'sweet', 'chili', 'sauce', 'rice', 'vinegar', 'tablespoons', 'asian', 'fish', 'sauce', 'peeled', 'grated', 'fresh', 'ginger', 'garlic', 'powder', 'cloves', 'garlic', 'finely', 'choppedcoarse', 'black', 'pepper', 'seasoning', 'gallon', 'shortening', 'oil', 'frying', 'chicken', 'wings', 'cleaned', 'dried']\":  11,\n",
      "  \"['velveeta', 'pasteurized', 'prepared', 'cheese', 'product', 'cut', 'inch', 'cubes', 'rotel', 'diced', 'tomatoes', 'green', 'chilies', 'undrained']\":  12,\n",
      "  \"['one', 'inchthick', 'london', 'broil', 'olive', 'oil', 'worcestershire', 'sauce', 'tablespoons', 'balsamic', 'vinegar', 'cloves', 'garlic', 'smashed', 'whole', 'sprigs', 'rosemary', 'plus', 'chopped', 'leaveskosher', 'salt', 'freshly', 'ground', 'black', 'pepper', 'strip', 'bacon', 'chopped', 'cremini', 'mushrooms', 'halved', 'panko', 'breadcrumbs', 'tablespoons', 'unsalted', 'butter', 'sour', 'cream', 'tablespoons', 'prepared', 'drained', 'horseradish', 'chopped', 'fresh', 'parsley', 'garnish']\":  13,\n",
      "  \"['duck', 'teaspoons', 'salt', 'teaspoons', 'freshly', 'ground', 'black', 'pepper', 'garlic', 'cloves', 'crushed', 'cinnamon', 'sticks', 'halved', 'cups', 'chicken', 'duck', 'fat', 'lard', 'olive', 'oil', 'onions', 'thinly', 'sliced', 'freshly', 'squeezed', 'lime', 'juicespiced', 'pineapple', 'lentils', 'recipe', 'follows', 'warmed']\":  14,\n",
      "  \"['cups', 'purpose', 'flour', 'cornmeal', 'salt', 'baking', 'powder', 'tablespoons', 'sugar', 'butter', 'cut', 'pieceswellchilled', 'frozen', 'vegetable', 'shortening', 'cut', 'pieceswellchilled', 'frozen', 'tablespoons', 'ice', 'water', 'vanilla', 'fresh', 'rhubarb', 'sliced', 'inch', 'pieces', 'pints', 'fresh', 'strawberries', 'thinly', 'sliced', 'cups', 'white', 'sugar', 'tablespoons', 'purpose', 'flour', 'vanilla', 'bean', 'split', 'scraped', 'tablespoons', 'unsalted', 'butter', 'tablespoons', 'crystallized', 'sugar', 'granulated', 'sugar', 'whole', 'egg', 'beaten']\":  15,\n",
      "  \"['boneless', 'skinless', 'chicken', 'breast', 'halves', 'lbs', 'egg', 'slightly', 'beaten', 'italian', 'seasoned', 'dry', 'bread', 'crumbs', 'ounces', 'thinly', 'sliced', 'prosciutto', 'deli', 'boiled', 'ham', 'bertolliÂ®', 'vineyard', 'premium', 'collections', 'marinara', 'burgundy', 'wine', 'sauce', 'ounces', 'fresh', 'mozzarella', 'cheese', 'thinly', 'sliced', 'ounces', 'spaghetti', 'cooked', 'drained']\":  16,\n",
      "  \"['bag', 'tortilla', 'chipsneelys', 'bbq', 'seasoning', 'ounces', 'chopped', 'pork', 'beef', 'chicken', 'ounces', 'neely', 'bbq', 'sauce', 'warm', 'recipe', 'follows', 'ounces', 'nacho', 'cheese', 'melted', 'sliced', 'jalapenos', 'drained', 'ounces', 'paprika', 'ounces', 'white', 'sugar', 'onion', 'powder', 'cups', 'ketchup', 'water', 'apple', 'cider', 'vinegar', 'tablespoons', 'light', 'brown', 'sugar', 'tablespoons', 'sugar', 'fresh', 'ground', 'black', 'pepper', 'onion', 'powder', 'ground', 'mustard', 'lemon', 'juice', 'worcestershire', 'sauce']\":  17,\n",
      "  \"['tablespoons', 'butter', 'onions', 'chopped', 'cornmeal', 'muffins', 'cubeda', 'handful', 'fresh', 'sage', 'leaves', 'chopped', 'egg', 'heavy', 'cream', 'chicken', 'stocksalt', 'freshly', 'ground', 'black', 'pepper']\":  18,\n",
      "  \"['fresh', 'florida', 'lobster', 'tails', 'extravirgin', 'olive', 'oil', 'onion', 'chopped', 'cloves', 'garlic', 'chopped', 'tomato', 'sauce', 'fish', 'stock', 'parsley', 'leaves', 'finely', 'chopped', 'white', 'cooking', 'wine', 'finely', 'chopped', 'scotch', 'bonnet', 'peppers', 'white', 'wine', 'vinegar', 'teaspoons', 'hot', 'sauce', 'teaspoons', 'salt', 'pepper', 'laurel', 'leaf']\":  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi    ['celery', 'finely', 'chopped', 'green', 'pepp...\n",
      "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO    ['skirt', 'steak', 'cut', 'inch', 'dicekosher'...\n",
      "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK    ['cups', 'dried', 'black', 'beans', 'picked', ...\n",
      "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK    ['ground', 'chuckone', 'tomato', 'sauce', 'sal...\n",
      "kRBQSWtqYWqtkb34FGeenBSbC32gIdO    ['rice', 'brown', 'mediumgrain', 'cookedcup', ...\n",
      "PmoGGX9RC5zbMJXtZH1SKzWKLFX4Aii    ['extravirgin', 'olive', 'oil', 'baby', 'itali...\n",
      "g2RYP1spIUlAYsytDMsdfLNQEOnLUrO    ['lightly', 'crumbled', 'saffron', 'threads', ...\n",
      "94NWE4F4C5NzgH0zYqSdmPM/G55BjKO    ['topsliced', 'hotdog', 'buns', 'fashion', 'to...\n",
      "HdIbPB/8cgk17hAzbc2jUN4VBn//QKS    ['green', 'red', 'bell', 'peppers', 'olive', '...\n",
      "mC7Nb4F2S.DMCjZ39kzS/ak9GqEp4iO    ['head', 'cauliflower', 'cut', 'bitesize', 'fl...\n",
      "QaFfhzgVliz840HdAnIypaGteQn5q3K    ['cups', 'chicken', 'stock', 'preferably', 'ho...\n",
      "2ZlbPBIZEDWBdGFcJ/KhApHyOTYvt.G    ['cups', 'sweet', 'chili', 'sauce', 'rice', 'v...\n",
      "8zGobobyDsaZYEw2dC0aOx5OMhA.TK6    ['velveeta', 'pasteurized', 'prepared', 'chees...\n",
      "Name: ingredients_vector, dtype: object ---- characters mapped to int ---- > [56784     1     2     3     4     5     6     7     8     9    10    11\n",
      "    12]\n"
     ]
    }
   ],
   "source": [
    "# Show how the first 13 characters from the text are mapped to integers\n",
    "print ('{} ---- characters mapped to int ---- > {}'.format(repr(df['ingredients_vector'][:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'simple white sangria'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c7831f5c33df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#one-hot encode target column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/Springboard/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mis\u001b[0m \u001b[0mplaced\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \"\"\"\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'simple white sangria'"
     ]
    }
   ],
   "source": [
    "#one-hot encode target column\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_8: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9aa54ec92cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model.compile(loss='categorical_crossentropy',\n",
      "\u001b[0;32m//anaconda3/envs/Springboard/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m//anaconda3/envs/Springboard/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/Springboard/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/Springboard/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_8: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(20, len(df))))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer='adam',\n",
    "          metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=1000)\n",
    "# x_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "# x_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
